{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Hadarmard matrix can be used as hash targets (hash centers) \n",
    "In this tutorial, we introduce how to use Hadamard matrix to generate hash targets (hash centers) for image and video datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import comb, perm  #calculate combination\n",
    "from itertools import combinations\n",
    "from scipy.linalg import hadamard  # direct import  hadamrd matrix from scipy\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a hadamard matrix. Each row or coloume can be used as a target for a class of images of videos in hashing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 64 # d is the lenth of hash codes and hash centers, d should be 2^n\n",
    "ha_d = hadamard(d)   # hadamard matrix \n",
    "ha_2d = np.concatenate((ha_d, -ha_d),0)  # can be used as targets for 2*d hash bit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next, we give examples for a single-label dataset and a multi-label dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Generating Hash targets for single-label dataset: ImageNet\n",
    "We sample 100 classes from ImageNet in experiment. So we generate 100 hash targets, one target for one spcifical class of data. For single-label datasets: ImageNet, UCF101 and HMDB51, the process of generating hash targets is the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hash centers shape: torch.Size([100, 64])\n"
     ]
    }
   ],
   "source": [
    "num_class = 100\n",
    "\n",
    "if num_class<=d:\n",
    "    hash_targets = torch.from_numpy(ha_d[0:num_class]).float()\n",
    "    print('hash centers shape: {}'. format(hash_targets.shape))\n",
    "elif num_class>d:\n",
    "    hash_targets = torch.from_numpy(ha_2d[0:num_class]).float()\n",
    "    print('hash centers shape: {}'. format(hash_targets.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the hash targets as training targets\n",
    "file_name = str(d) + '_imagenet' + '_' + str(num_class) + '_class.pkl'\n",
    "file_dir = 'data/imagenet/hash_centers/' + file_name\n",
    "f = open(file_dir, \"wb\")\n",
    "torch.save(hash_targets, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test average Hamming distance between hash targets\n",
    "b = []\n",
    "num_class= 100\n",
    "for i in range(0, num_class):\n",
    "    b.append(i)\n",
    "com_num = int(comb(num_class, 2))\n",
    "c = np.zeros(com_num)\n",
    "for i in range(com_num):\n",
    "    i_1 = list(combinations(b, 2))[i][0]\n",
    "    i_2 = list(combinations(b, 2))[i][1]\n",
    "    TF = sum(hash_targets[i_1]!=hash_targets[i_2])\n",
    "    c[i]=TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([32., 32., 32., ..., 32., 32., 32.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# distance between any two hash targets\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Generating Hash targets for multi-label dataset: NUS_WIDE\n",
    "\n",
    "We use 21 classes from NUS_WIDE in experiment. We first generate 21 hash targets, one target for one spcifical class of data; Then, we caculate the centroid for multi-label data. For multi-label datasets: COCO and NUS_WIDE, the process of generating hash centers is the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hash centers shape: torch.Size([21, 64])\n"
     ]
    }
   ],
   "source": [
    "num_class = 21\n",
    "if num_class<=d:\n",
    "    hash_targets = torch.from_numpy(ha_d[0:num_class]).float()\n",
    "    print('hash centers shape: {}'. format(hash_targets.shape))\n",
    "elif num_class>d:\n",
    "    hash_targets = torch.from_numpy(ha_2d[0:num_class]).float()\n",
    "    print('hash centers shape: {}'. format(hash_targets.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the hash targets as training targets\n",
    "file_name = str(d) + '_nus_wide' + '_' + str(num_class) + '_class.pkl'\n",
    "file_dir = 'data/nus_wide/hash_centers/' + file_name\n",
    "f = open(file_dir, \"wb\")\n",
    "torch.save(hash_targets, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi_label centers generation for NUS_WIDE\n",
    "One simple example, if one image in NUS_WIDE has a smantical label as: [1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1]\n",
    "So the image contains three types of objects, including the first, second and the last class. Then we caculate the centroid of the three corresponding centers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "          1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "          1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "          1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "          1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "        [ 1., -1.,  1., -1.,  1., -1.,  1., -1.,  1., -1.,  1., -1.,  1., -1.,\n",
       "          1., -1.,  1., -1.,  1., -1.,  1., -1.,  1., -1.,  1., -1.,  1., -1.,\n",
       "          1., -1.,  1., -1.,  1., -1.,  1., -1.,  1., -1.,  1., -1.,  1., -1.,\n",
       "          1., -1.,  1., -1.,  1., -1.,  1., -1.,  1., -1.,  1., -1.,  1., -1.,\n",
       "          1., -1.,  1., -1.,  1., -1.,  1., -1.],\n",
       "        [ 1.,  1.,  1.,  1., -1., -1., -1., -1.,  1.,  1.,  1.,  1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1.,  1.,  1.,  1.,  1., -1., -1., -1., -1.,\n",
       "          1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1., -1., -1., -1.,  1.,  1.,\n",
       "          1.,  1., -1., -1., -1., -1., -1., -1., -1., -1.,  1.,  1.,  1.,  1.,\n",
       "         -1., -1., -1., -1.,  1.,  1.,  1.,  1.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = torch.tensor([1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1])\n",
    "three_centers = hash_targets[label==1]\n",
    "three_centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.,  1.,  1.,  1.,  1., -1.,  1., -1.,  1.,  1.,  1.,  1.,  1., -1.,\n",
       "         1., -1.,  1., -1.,  1., -1.,  1.,  1.,  1.,  1.,  1., -1.,  1., -1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1., -1.,  1.,  1.,\n",
       "         1.,  1.,  1., -1.,  1., -1.,  1., -1.,  1., -1.,  1.,  1.,  1.,  1.,\n",
       "         1., -1.,  1., -1.,  1.,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroid = three_centers.mean(dim=0)\n",
    "centroid[centroid>0]=1.0\n",
    "centroid[centroid<0]=-1.0\n",
    "centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Generating hash targets by sampling from Bernouli distribution\n",
    "\n",
    "We just give an example for generating hash center for ImageNet@64bit. The generation for other datasets is the same. And the centroid caculation is similarity with the above process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.0\n",
      "48.0\n",
      "32.02383838383838\n",
      "18.0\n",
      "46.0\n",
      "32.00525252525252\n",
      "16.0\n",
      "48.0\n",
      "32.00646464646464\n",
      "20.0\n",
      "46.0\n",
      "31.986666666666668\n",
      "20.0\n",
      "46.0\n",
      "31.933333333333334\n",
      "18.0\n",
      "44.0\n",
      "31.93010101010101\n",
      "18.0\n",
      "46.0\n",
      "32.01979797979798\n",
      "16.0\n",
      "46.0\n",
      "31.90707070707071\n",
      "18.0\n",
      "46.0\n",
      "31.90141414141414\n",
      "18.0\n",
      "46.0\n",
      "32.05777777777778\n",
      "18.0\n",
      "46.0\n",
      "31.97939393939394\n",
      "18.0\n",
      "46.0\n",
      "32.02383838383838\n",
      "18.0\n",
      "46.0\n",
      "32.08888888888889\n",
      "18.0\n",
      "46.0\n",
      "31.988282828282827\n",
      "20.0\n",
      "46.0\n",
      "32.034747474747476\n",
      "20.0\n",
      "stop! we find suitable hash centers\n"
     ]
    }
   ],
   "source": [
    "# random generation\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import csv\n",
    "from scipy.special import comb, perm  #calculate combination\n",
    "from itertools import combinations\n",
    "hash_targets = []\n",
    "a = []  # for sampling the 0.5*hash_bit \n",
    "b = []  # for calculate the combinations of 51 num_class\n",
    "num_class = 100\n",
    "hash_bit = 64\n",
    "\n",
    "\n",
    "for i in range(0, hash_bit):\n",
    "        a.append(i)\n",
    "\n",
    "for i in range(0, num_class):\n",
    "    b.append(i)\n",
    "    \n",
    "for j in range(10000):\n",
    "    hash_targets = torch.zeros([num_class, hash_bit])\n",
    "    for i in range(num_class):\n",
    "        ones = torch.ones(hash_bit)\n",
    "        sa = random.sample(a, round(hash_bit/2))\n",
    "        ones[sa] = -1\n",
    "        hash_targets[i]=ones\n",
    "    com_num = int(comb(num_class, 2))\n",
    "    c = np.zeros(com_num)\n",
    "    for i in range(com_num):\n",
    "        i_1 = list(combinations(b, 2))[i][0]\n",
    "        i_2 = list(combinations(b, 2))[i][1]\n",
    "        TF = torch.sum(hash_targets[i_1]!=hash_targets[i_2])\n",
    "        c[i]=TF\n",
    "    print(min(c))\n",
    "    print(max(c))\n",
    "    print(np.mean(c))\n",
    "\n",
    "\n",
    "    if min(c)>=20 and np.mean(c)>=32:  # guarantee the hash center are far away from each other in Hamming space, 20 can be set as 18 for fast convergence\n",
    "        print(min(c))\n",
    "        print(\"stop! we find suitable hash centers\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the hash targets as training targets\n",
    "file_name = str(d) + '_imagenet' + '_' + str(num_class) + '_class_random.pkl'\n",
    "file_dir = 'data/imagenet/hash_centers/' + file_name\n",
    "f = open(file_dir, \"wb\")\n",
    "torch.save(hash_targets, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py3.5)",
   "language": "python",
   "name": "py3.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
